{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet34\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import normalize, to_pil_image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement et prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Nombre de classes : 10\n"
     ]
    }
   ],
   "source": [
    "# Configuration des paramètres\n",
    "batch_size = 32\n",
    "\n",
    "# Transformations pour CIFAR-10\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Agrandir les images à 224x224 pour ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),  # CIFAR-10 stats\n",
    "])\n",
    "\n",
    "# Chargement des données CIFAR-10\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle ResNet pour les caractéristiques\n",
    "class ProtoPNet(nn.Module):\n",
    "    def __init__(self, num_prototypes, num_classes):\n",
    "        super(ProtoPNet, self).__init__()\n",
    "        # Backbone CNN (ResNet-34 sans la couche fully connected)\n",
    "        self.backbone = resnet34(pretrained=True)\n",
    "        self.backbone.fc = nn.Identity()  # Supprimer la dernière couche FC\n",
    "        self.feature_dim = 512  # Dimension de sortie de ResNet-34\n",
    "\n",
    "        # Couche prototype\n",
    "        self.prototype_layer = nn.Parameter(torch.randn(num_prototypes, self.feature_dim))\n",
    "\n",
    "        # Couche fully connected\n",
    "        self.fc = nn.Linear(num_prototypes, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extraire les caractéristiques\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # Calcul des similarités (distance L2)\n",
    "        distances = torch.cdist(features.unsqueeze(1), self.prototype_layer.unsqueeze(0), p=2) # J'ai retiré le double \"unsqueeze(1)\" parce que ça compilait pas mais c'est dans l'article normalement\n",
    "        similarities = -distances.squeeze(2)  # Les similarités sont inversées des distances\n",
    "\n",
    "        # Agrégation et classification\n",
    "        max_similarities = similarities.max(dim=1).values\n",
    "        output = self.fc(max_similarities)\n",
    "\n",
    "        return output, max_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahol/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/fahol/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparamètres\n",
    "num_prototypes = num_classes * 10  # 10 prototypes par classe\n",
    "model = ProtoPNet(num_prototypes=num_prototypes, num_classes=num_classes).to(\"cpu\")\n",
    "\n",
    "# Optimiseur et scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Fonction de perte\n",
    "def loss_function(outputs, targets, max_similarities, lambda_clst=0.8, lambda_sep=0.2):\n",
    "    classification_loss = F.cross_entropy(outputs, targets)\n",
    "\n",
    "    # Perte de regroupement et séparation\n",
    "    clst_loss = -max_similarities[range(targets.size(0)), targets].mean()\n",
    "    sep_loss = max_similarities.mean()\n",
    "\n",
    "    return classification_loss + lambda_clst * clst_loss + lambda_sep * sep_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Début de l'époque 1\n",
      "Batch 1/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 21.7934\n",
      "Batch 2/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 22.0176\n",
      "Batch 3/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 20.2943\n",
      "Batch 4/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.1684\n",
      "Batch 5/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 20.1055\n",
      "Batch 6/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 20.4590\n",
      "Batch 7/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.8114\n",
      "Batch 8/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.4816\n",
      "Batch 9/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 19.7474\n",
      "Batch 10/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.9836\n",
      "Batch 11/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 19.2215\n",
      "Batch 12/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 20.5718\n",
      "Batch 13/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.8014\n",
      "Batch 14/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.2659\n",
      "Batch 15/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.7777\n",
      "Batch 16/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 20.1656\n",
      "Batch 17/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.1900\n",
      "Batch 18/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.1578\n",
      "Batch 19/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.5850\n",
      "Batch 20/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.2129\n",
      "Batch 21/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.1282\n",
      "Batch 22/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.2356\n",
      "Batch 23/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.8475\n",
      "Batch 24/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.7414\n",
      "Batch 25/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.2356\n",
      "Batch 26/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.4267\n",
      "Batch 27/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.5229\n",
      "Batch 28/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 18.1809\n",
      "Batch 29/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.6829\n",
      "Batch 30/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.1124\n",
      "Batch 31/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.2624\n",
      "Batch 32/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.9442\n",
      "Batch 33/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.5480\n",
      "Batch 34/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.3405\n",
      "Batch 35/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.6109\n",
      "Batch 36/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.6921\n",
      "Batch 37/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.6933\n",
      "Batch 38/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 17.2904\n",
      "Batch 39/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.9958\n",
      "Batch 40/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.7080\n",
      "Batch 41/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.8322\n",
      "Batch 42/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.6954\n",
      "Batch 43/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.1607\n",
      "Batch 44/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.8283\n",
      "Batch 45/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.7612\n",
      "Batch 46/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.5179\n",
      "Batch 47/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.0606\n",
      "Batch 48/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.9980\n",
      "Batch 49/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.3385\n",
      "Batch 50/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.6802\n",
      "Batch 51/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.3383\n",
      "Batch 52/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.1948\n",
      "Batch 53/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.4267\n",
      "Batch 54/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.9751\n",
      "Batch 55/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.8692\n",
      "Batch 56/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.4772\n",
      "Batch 57/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.2262\n",
      "Batch 58/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 16.1307\n",
      "Batch 59/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.5276\n",
      "Batch 60/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.2071\n",
      "Batch 61/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.6733\n",
      "Batch 62/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.4471\n",
      "Batch 63/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.5654\n",
      "Batch 64/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.4113\n",
      "Batch 65/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.2996\n",
      "Batch 66/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.9118\n",
      "Batch 67/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.6221\n",
      "Batch 68/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.5280\n",
      "Batch 69/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.8063\n",
      "Batch 70/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.3624\n",
      "Batch 71/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2652\n",
      "Batch 72/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.0208\n",
      "Batch 73/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.9389\n",
      "Batch 74/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.8665\n",
      "Batch 75/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.3121\n",
      "Batch 76/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.5564\n",
      "Batch 77/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.4140\n",
      "Batch 78/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.3579\n",
      "Batch 79/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.7925\n",
      "Batch 80/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.8287\n",
      "Batch 81/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.8770\n",
      "Batch 82/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.0957\n",
      "Batch 83/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.0868\n",
      "Batch 84/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.9643\n",
      "Batch 85/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.5339\n",
      "Batch 86/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.7818\n",
      "Batch 87/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.7798\n",
      "Batch 88/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.0059\n",
      "Batch 89/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.5596\n",
      "Batch 90/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.5068\n",
      "Batch 91/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.7777\n",
      "Batch 92/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.4328\n",
      "Batch 93/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3637\n",
      "Batch 94/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.6388\n",
      "Batch 95/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 15.0600\n",
      "Batch 96/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.5555\n",
      "Batch 97/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3369\n",
      "Batch 98/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2893\n",
      "Batch 99/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2561\n",
      "Batch 100/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.4955\n",
      "Batch 101/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.4256\n",
      "Batch 102/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.0501\n",
      "Batch 103/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3816\n",
      "Batch 104/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2792\n",
      "Batch 105/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3812\n",
      "Batch 106/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.9730\n",
      "Batch 107/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.8170\n",
      "Batch 108/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3112\n",
      "Batch 109/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2370\n",
      "Batch 110/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3485\n",
      "Batch 111/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.6967\n",
      "Batch 112/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.5963\n",
      "Batch 113/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.5435\n",
      "Batch 114/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.5811\n",
      "Batch 115/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2710\n",
      "Batch 116/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.0539\n",
      "Batch 117/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.4263\n",
      "Batch 118/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.7865\n",
      "Batch 119/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4826\n",
      "Batch 120/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.1030\n",
      "Batch 121/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.8778\n",
      "Batch 122/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4153\n",
      "Batch 123/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.0874\n",
      "Batch 124/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.8222\n",
      "Batch 125/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.5717\n",
      "Batch 126/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.2836\n",
      "Batch 127/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.9743\n",
      "Batch 128/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.8767\n",
      "Batch 129/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.1405\n",
      "Batch 130/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.8989\n",
      "Batch 131/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.8884\n",
      "Batch 132/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.8448\n",
      "Batch 133/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.3079\n",
      "Batch 134/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.0436\n",
      "Batch 135/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.5686\n",
      "Batch 136/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.2944\n",
      "Batch 137/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.0551\n",
      "Batch 138/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 14.3318\n",
      "Batch 139/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.2601\n",
      "Batch 140/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.7160\n",
      "Batch 141/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.0951\n",
      "Batch 142/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.6713\n",
      "Batch 143/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.1221\n",
      "Batch 144/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.7560\n",
      "Batch 145/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.9262\n",
      "Batch 146/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.6837\n",
      "Batch 147/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4124\n",
      "Batch 148/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.7911\n",
      "Batch 149/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.2866\n",
      "Batch 150/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.6322\n",
      "Batch 151/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.4211\n",
      "Batch 152/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4154\n",
      "Batch 153/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.0406\n",
      "Batch 154/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.1742\n",
      "Batch 155/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.0948\n",
      "Batch 156/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.2064\n",
      "Batch 157/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4025\n",
      "Époque 1 terminée, Perte moyenne : 1.5539\n",
      "\n",
      "Début de l'époque 2\n",
      "Batch 1/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.1231\n",
      "Batch 2/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.7543\n",
      "Batch 3/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.8801\n",
      "Batch 4/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.9746\n",
      "Batch 5/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.8081\n",
      "Batch 6/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.3046\n",
      "Batch 7/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.0751\n",
      "Batch 8/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.9928\n",
      "Batch 9/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.9252\n",
      "Batch 10/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4241\n",
      "Batch 11/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4641\n",
      "Batch 12/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.3645\n",
      "Batch 13/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.6524\n",
      "Batch 14/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.6847\n",
      "Batch 15/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.5169\n",
      "Batch 16/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.2721\n",
      "Batch 17/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.5614\n",
      "Batch 18/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.6625\n",
      "Batch 19/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.2916\n",
      "Batch 20/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.7770\n",
      "Batch 21/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.3083\n",
      "Batch 22/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.3395\n",
      "Batch 23/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.2031\n",
      "Batch 24/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 11.9918\n",
      "Batch 25/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.2534\n",
      "Batch 26/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.9983\n",
      "Batch 27/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.0675\n",
      "Batch 28/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.1554\n",
      "Batch 29/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.9356\n",
      "Batch 30/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.2480\n",
      "Batch 31/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.9135\n",
      "Batch 32/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.8210\n",
      "Batch 33/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.8263\n",
      "Batch 34/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.2809\n",
      "Batch 35/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.4265\n",
      "Batch 36/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 11.8206\n",
      "Batch 37/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.0518\n",
      "Batch 38/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.5121\n",
      "Batch 39/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.7658\n",
      "Batch 40/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 13.4347\n",
      "Batch 41/156:\n",
      "  Sorties du modèle (outputs) : torch.Size([32, 10])\n",
      "  Max Similarities : torch.Size([32, 100])\n",
      "  Perte pour ce batch : 12.1426\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Rétropropagation\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 30\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Mise à jour du scheduler\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # 20 époques\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    print(f\"\\nDébut de l'époque {epoch + 1}\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        if batch_idx >= len(train_loader)//10: # Limite à 156 car 1563 c'est long\n",
    "            break\n",
    "\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "\n",
    "        # Passer les données à travers le modèle\n",
    "        outputs, max_similarities = model(images)\n",
    "        \n",
    "        # Impression des dimensions des sorties\n",
    "        print(f\"Batch {batch_idx + 1}/{len(train_loader)//10}:\")\n",
    "        print(f\"  Sorties du modèle (outputs) : {outputs.shape}\")\n",
    "        print(f\"  Max Similarities : {max_similarities.shape}\")\n",
    "\n",
    "        # Calcul de la perte\n",
    "        loss = loss_function(outputs, labels, max_similarities)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Impression de la perte pour le batch\n",
    "        print(f\"  Perte pour ce batch : {loss.item():.4f}\")\n",
    "\n",
    "        # Rétropropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Mise à jour du scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Impression de la perte moyenne après chaque époque\n",
    "    print(f\"Époque {epoch + 1} terminée, Perte moyenne : {total_loss / (len(train_loader)//10):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour normaliser les images d'origine pour la visualisation\n",
    "def denormalize_image(image_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).cuda()\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).cuda()\n",
    "    return image_tensor * std + mean\n",
    "\n",
    "def find_prototype_matches(model, train_loader, num_prototypes):\n",
    "    model.eval()\n",
    "    prototype_matches = {i: {\"image\": None, \"patch\": None, \"activation\": -float('inf')} for i in range(num_prototypes)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in train_loader:\n",
    "            images = images.cuda()\n",
    "            features = model.backbone(images)  # Extraire les caractéristiques\n",
    "            features = features.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "            # Calculer les activations des prototypes\n",
    "            distances = torch.cdist(features, model.prototype_layer, p=2)\n",
    "            similarities = -distances  # Les similarités sont inversées des distances\n",
    "\n",
    "            # Pour chaque prototype, trouver le patch avec l'activation maximale\n",
    "            for prototype_idx in range(num_prototypes):\n",
    "                max_similarity, max_index = similarities[:, prototype_idx].view(-1).max(0)\n",
    "                if max_similarity.item() > prototype_matches[prototype_idx][\"activation\"]:\n",
    "                    prototype_matches[prototype_idx][\"image\"] = images[max_index].cpu()\n",
    "                    prototype_matches[prototype_idx][\"patch\"] = features[max_index].cpu()\n",
    "                    prototype_matches[prototype_idx][\"activation\"] = max_similarity.item()\n",
    "\n",
    "    return prototype_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prototypes(prototype_matches, save_dir=\"prototypes\"):\n",
    "    import os\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for idx, match in prototype_matches.items():\n",
    "        if match[\"image\"] is None:\n",
    "            continue\n",
    "\n",
    "        # Convertir le tensor en image\n",
    "        original_image = denormalize_image(match[\"image\"]).clamp(0, 1)\n",
    "        original_image_pil = to_pil_image(original_image)\n",
    "\n",
    "        # Sauvegarder l'image originale\n",
    "        original_image_pil.save(f\"{save_dir}/prototype_{idx}_original.png\")\n",
    "\n",
    "        # Visualiser le prototype\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "        ax.imshow(original_image_pil)\n",
    "        ax.set_title(f\"Prototype {idx}\")\n",
    "        ax.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{save_dir}/prototype_{idx}_visualization.png\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(image, activation_map):\n",
    "    # Redimensionner la carte d'activation à la taille de l'image\n",
    "    activation_map_resized = cv2.resize(activation_map, (image.size[0], image.size[1]))\n",
    "\n",
    "    # Normaliser la carte pour les valeurs de 0 à 1\n",
    "    activation_map_resized = (activation_map_resized - activation_map_resized.min()) / (activation_map_resized.max() - activation_map_resized.min())\n",
    "\n",
    "    # Superposer la carte d'activation à l'image originale\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * activation_map_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    superimposed = cv2.addWeighted(np.array(image), 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    return superimposed\n",
    "\n",
    "def visualize_heatmaps(model, prototype_matches, save_dir=\"heatmaps\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for idx, match in prototype_matches.items():\n",
    "        if match[\"image\"] is None:\n",
    "            continue\n",
    "\n",
    "        # Convertir le tensor en image\n",
    "        original_image = denormalize_image(match[\"image\"]).clamp(0, 1)\n",
    "        original_image_pil = to_pil_image(original_image)\n",
    "\n",
    "        # Obtenir l'activation maximale pour ce prototype\n",
    "        activation_map = match[\"patch\"].view(-1).numpy()\n",
    "\n",
    "        # Générer la carte de chaleur\n",
    "        heatmap = generate_heatmap(original_image_pil, activation_map)\n",
    "\n",
    "        # Sauvegarder la carte de chaleur\n",
    "        plt.imsave(f\"{save_dir}/prototype_{idx}_heatmap.png\", heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les correspondances avec les prototypes\n",
    "prototype_matches = find_prototype_matches(model, train_loader, num_prototypes=num_prototypes)\n",
    "\n",
    "# Visualiser les prototypes originaux\n",
    "visualize_prototypes(prototype_matches, save_dir=\"prototypes\")\n",
    "\n",
    "# Générer et sauvegarder les cartes de chaleur\n",
    "visualize_heatmaps(model, prototype_matches, save_dir=\"heatmaps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs, _ = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"Précision : {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
